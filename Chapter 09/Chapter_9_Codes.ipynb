{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP3eEzBpRPlF"
      },
      "outputs": [],
      "source": [
        "#Code:\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#Loading the data\n",
        "Data=load_iris()\n",
        "X=Data.data\n",
        "Y=Data.target\n",
        "\n",
        "#Consider only two classes\n",
        "X=X[:100,:]\n",
        "y=Y[:100]\n",
        "#Train test split\n",
        "\n",
        "X, y = shuffle(X, y, random_state=0)\n",
        "X_train=X[:80,:]\n",
        "y_train=y[:80]\n",
        "X_test=X[80:,:]\n",
        "y_test=y[80:]\n",
        "\n",
        "#Setting parameters\n",
        "alpha=0.01\n",
        "m=X.shape[1]\n",
        "\n",
        "#Initial weights and bais\n",
        "w=np.random.rand(m)\n",
        "b=np.random.rand()\n",
        "n=(X_train.shape[0])\n",
        "\n",
        "#Learning: The Rosenblatt Perceptron\n",
        "for i in range(n):\n",
        "  X1=X_train[i,:]\n",
        "  u=np.matmul(X1,np.transpose(w))\n",
        "  v=1/(1+np.exp(-1*u))\n",
        "  if (v>0.5):\n",
        "    o1=1\n",
        "  else:\n",
        "    o1=0\n",
        "  #print(v,' ',y_train[i])\n",
        "  y1=y_train[i]\n",
        "  w=w-alpha*(o1-y1)*X1\n",
        "  b=b-alpha*(o1-y1)\n",
        "\n",
        "#Finding accuracy, specificity and senstivity\n",
        "tp=0\n",
        "tn=0\n",
        "fp=0\n",
        "fn=0\n",
        "for i in range(20):\n",
        "  X1=X_test[i,:]\n",
        "  u=np.matmul(X1,np.transpose(w))+b\n",
        "  v=1/(1+np.exp(-1*u))\n",
        "  if (v>0.5):\n",
        "    o1=1\n",
        "  else:\n",
        "    o1=0\n",
        "  y1=y_test[i]\n",
        "  if(o1==1 &y1==1):\n",
        "    tp+=1\n",
        "  elif(o1==0 &y1==0):\n",
        "    tn+=1\n",
        "  elif(o1==1 &y1==0):\n",
        "    fp+=1\n",
        "  else:\n",
        "    fn+=1\n",
        "\n",
        "acc=(tp+tn)/(tp+tn+fp+fn)*100\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 1: Classification of Fisher Iris Data\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#Load Data\n",
        "IRIS=load_iris()\n",
        "X=IRIS.data\n",
        "y=IRIS.target\n",
        "\n",
        "#Normalize\n",
        "max=[]\n",
        "min=[]\n",
        "S=X.shape\n",
        "for i in range(S[1]):\n",
        "  max.append(np.max(X[:,i]))\n",
        "  min.append(np.min(X[:,i]))\n",
        "for i in range(S[1]):\n",
        "  for j in range(S[0]):\n",
        "      X[j,i]=(X[j,i]-min[i])/(max[i]-min[i])\n",
        "\n",
        "#Prepare test train data\n",
        "arr=np.random.permutation(100)\n",
        "X=IRIS.data[arr,:]\n",
        "y=np.vstack((np.zeros((50,1)),np.ones((50,1))))\n",
        "y=y[arr]\n",
        "X_train=X[:40,:]\n",
        "X_test=X[40:50,:]\n",
        "y_train=y[:40]\n",
        "y_test=y[40:50]\n",
        "X_train1=X[50:90,:]\n",
        "X_test1=X[90:100,:]\n",
        "y_train1=y[50:90]\n",
        "y_test1=y[90:100]\n",
        "X_train=np.vstack((X_train,X_train1))\n",
        "y_train=np.vstack((y_train,y_train1))\n",
        "X_test=np.vstack((X_test,X_test1))\n",
        "y_test=np.vstack((y_test,y_test1))\n",
        "\n",
        "#Classify using SLP\n",
        "clf=Perceptron(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "predicted=clf.predict(X_test)\n",
        "TP=0\n",
        "TN=0\n",
        "FN=0\n",
        "FP=0\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==predicted[i]):\n",
        "    if(y_test[i]==1):\n",
        "      TP+=1\n",
        "    else:\n",
        "      TN+=1\n",
        "  else:\n",
        "    if(predicted[i]==1):\n",
        "      FP+=1\n",
        "    else:\n",
        "      FN+=1\n",
        "acc=(TP+TN)/(TP+TN+FP+FN)      #accuracy\n",
        "sens=TP/(TP+FN)                #sensitivity\n",
        "spec=TN/(TN+FP)                #specificity\n",
        "print(acc, sens, spec)\n"
      ],
      "metadata": {
        "id": "xiP9foZeSX1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 2: Classification of Fisher Iris Data, train-test split\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#Load Data\n",
        "IRIS=load_iris()\n",
        "X=IRIS.data\n",
        "y=IRIS.target\n",
        "\n",
        "#Normalize\n",
        "max=[]\n",
        "min=[]\n",
        "S=X.shape\n",
        "for i in range(S[1]):\n",
        "  max.append(np.max(X[:,i]))\n",
        "  min.append(np.min(X[:,i]))\n",
        "for i in range(S[1]):\n",
        "  for j in range(S[0]):\n",
        "    X[j,i]=(X[j,i]-min[i])/(max[i]-min[i])\n",
        "\n",
        "#Train test split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=4)\n",
        "\n",
        "#Predict using SLP\n",
        "clf=Perceptron(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "predicted=clf.predict(X_test)\n",
        "TP=0\n",
        "TN=0\n",
        "FN=0\n",
        "FP=0\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==predicted[i]):\n",
        "    if(y_test[i]==1):\n",
        "      TP+=1\n",
        "    else:\n",
        "      TN+=1\n",
        "  else:\n",
        "    if(predicted[i]==1):\n",
        "      FP+=1\n",
        "    else:\n",
        "      FN+=1\n",
        "acc=(TP+TN)/(TP+TN+FP+FN)      #accuracy\n",
        "sens=TP/(TP+FN)                #sensitivity\n",
        "spec=TN/(TN+FP)                #specificity\n",
        "print(acc, sens, spec)\n"
      ],
      "metadata": {
        "id": "FcyAcvSlSekp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 3: Classification of Breast Cancer Data\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#Load Data\n",
        "dataset=load_breast_cancer()       #constructor called\n",
        "X=dataset.data\n",
        "y=dataset.target\n",
        "#Normalize\n",
        "max=[]\n",
        "min=[]\n",
        "S=X.shape\n",
        "for i in range(S[1]):\n",
        "  max.append(np.max(X[:,i]))\n",
        "  min.append(np.min(X[:,i]))\n",
        "for i in range(S[1]):\n",
        "  for j in range(S[0]):\n",
        "    X[j,i]=(X[j,i]-min[i])/(max[i]-min[i])\n",
        "\n",
        "#Train test data\n",
        "X_train=X[:400,:]\n",
        "X_test=X[400:,:]\n",
        "y_train=y[:400]\n",
        "y_test=y[400:]\n",
        "\n",
        "#Classify using Perceptron\n",
        "clf=Perceptron(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "predicted=clf.predict(X_test)\n",
        "TP=0\n",
        "TN=0\n",
        "FN=0\n",
        "FP=0\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==predicted[i]):\n",
        "    if(y_test[i]==1):\n",
        "      TP+=1\n",
        "    else:\n",
        "      TN+=1\n",
        "  else:\n",
        "    if(predicted[i]==1):\n",
        "      FP+=1\n",
        "    else:\n",
        "      FN+=1\n",
        "acc=(TP+TN)/(TP+TN+FP+FN)      #accuracy\n",
        "sens=TP/(TP+FN)                #sensitivity\n",
        "spec=TN/(TN+FP)                #specificity\n",
        "print(acc, sens, spec)\n"
      ],
      "metadata": {
        "id": "vX4X8OPqSi4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 4: Classification of Breast Cancer Data, 10 Fold Validation\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#Load dataset\n",
        "dataset=load_breast_cancer()\n",
        "X=dataset.data\n",
        "y=dataset.target\n",
        "\n",
        "#K Fold\n",
        "kf=KFold(n_splits=10,random_state=None,shuffle=True)\n",
        "kf.get_n_splits(X)\n",
        "\n",
        "#Classification Using Perceptron\n",
        "accur=[]\n",
        "specificity=[]\n",
        "senstivity=[]\n",
        "for train_index, test_index in kf.split(X):\n",
        "  print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  clf=Perceptron(random_state=0)\n",
        "  clf.fit(X_train, y_train)\n",
        "  predicted=clf.predict(X_test)\n",
        "  TP=0\n",
        "  TN=0\n",
        "  FN=0\n",
        "  FP=0\n",
        "  for i in range(len(y_test)):\n",
        "    if(y_test[i]==predicted[i]):\n",
        "      if(y_test[i]==1):\n",
        "        TP+=1\n",
        "      else:\n",
        "        TN+=1\n",
        "    else:\n",
        "      if(predicted[i]==1):\n",
        "        FP+=1\n",
        "      else:\n",
        "        FN+=1\n",
        "  acc=(TP+TN)/(TP+TN+FP+FN)\n",
        "  accur.append(acc)\n",
        "  sens=TP/(TP+FN)\n",
        "  senstivity.append(sens)\n",
        "  spec=TN/(TN+FP)\n",
        "  specificity.append(spec)\n",
        "\n",
        "#Performance\n",
        "print(np.mean(accur))\n",
        "print(np.mean(senstivity))\n",
        "print(np.mean(specificity))\n"
      ],
      "metadata": {
        "id": "IYnOoSNHSnWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MGK2CT8XSsL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}