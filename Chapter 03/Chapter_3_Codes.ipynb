{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2Vum8rA3y9E"
      },
      "outputs": [],
      "source": [
        "#Selecting features using variance threshold\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "X, y=load_data()\n",
        "sel = VarianceThreshold(threshold=(.9* (1 - .9)))\n",
        "sel.fit_transform(X)\n",
        "print(sel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Load Data\n",
        "data1= load_wine()\n",
        "X = data1.data\n",
        "y = data1.target\n",
        "#Print the shape of X, and y\n",
        "print(X.shape, y.shape)\n",
        "#The following code finds the accuracy corresponding to the features selected so far\n",
        "Accuracy=[]\n",
        "Number_features=[]\n",
        "for threshold in np.linspace(0.01, 0.3, 20):\n",
        "   model = VarianceThreshold(threshold)\n",
        "\t X_Selected= model.fit_transform(X)\n",
        "\t #print(X_Selected.shape)\n",
        "\t X_train, X_test, y_train, y_test = train_test_split(X_Selected, y, test_size=0.3)\n",
        "\t model1 = SVC()\n",
        "\t model1.fit(X_train, y_train)\n",
        "\t y_pred=model1.predict(X_test)\n",
        "\t acc=np.sum(y_pred==y_test)/y_test.shape[0]\n",
        "\t Accuracy.append(acc)\n",
        "\t #print(acc, end=' ')\n",
        "\t Number_features.append(X_Selected.shape[1])\n",
        "plt.plot(Number_features, Accuracy, '.')\n"
      ],
      "metadata": {
        "id": "qchit1aP4Mcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "departments=df['Department'].unique()\n",
        "print(departments)\n",
        "patent_values=df['Patent'].unique()\n",
        "print(patent_values)\n",
        "table=np.zeros((2,3))\n",
        "i=0\n",
        "j=0\n",
        "for dept in departments:\n",
        "  j=0\n",
        "  for val in patent_values:\n",
        "    a=(df[(df['Department']==dept) & (df['Patent']==val)].count())\n",
        "    table[i,j]=a[0]\n",
        "    j+=1\n",
        "  i+=1\n",
        "print(table)"
      ],
      "metadata": {
        "id": "mVUv9ioU4ouP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2\n",
        "value, p_value, d_of_freedom, expected = chi2_contingency (table)\n",
        "print(expected)\n",
        "probability = 0.95\n",
        "critical = chi2.ppf(probability, d_of_freedom)\n",
        "if abs(value) >= critical:\n",
        "   print('The variables are Dependent')\n",
        "else:\n",
        "   print('The variables are not Dependent')\n",
        "alpha = 1.0 - probability\n",
        "print('significance=%.2f, p=%.2f' % (alpha, p_value))\n",
        "if p_value<= alpha:\n",
        "   print('Reject')\n",
        "else:\n",
        "   print('Do not reject')\n"
      ],
      "metadata": {
        "id": "Zb6sv9Bh5Ylm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "   Data=load_iris()\n",
        "   data=Data.data\n",
        "   target=Data.target\n",
        "   return (data, target)"
      ],
      "metadata": {
        "id": "90rFTD9r5iuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pearson_cor(X,y):\n",
        "  corr=[]\n",
        "  for i in range(X.shape[1]):\n",
        "     x=X[:,i]\n",
        "    x_mean=np.mean(x)\n",
        "    y_mean=np.mean(y)\n",
        "    x1=x-x_mean\n",
        "    y1=y-y_mean\n",
        "    prod=x1*y1\n",
        "    num=np.sum(prod)\n",
        "    den=np.sqrt((np.sum(x1*x1))*(np.sum(y1*y1)))\n",
        "    c=num/den\n",
        "    corr.append(c)\n",
        "return corr\n"
      ],
      "metadata": {
        "id": "O90g2RNT5lVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=load_data()\n",
        "corr=pearson_cor(X,y)\n",
        "feat=np.argsort(np.abs(corr))\n",
        "print(feat)"
      ],
      "metadata": {
        "id": "5Dre36Bf50xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recursive Feature Elimination\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVR\n",
        "X, y = load_boston().data, load_boston().target\n",
        "#print(X.shape)\n",
        "estimator = SVR(kernel=\"linear\")\n",
        "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
        "selector = selector.fit(X, y)\n",
        "print(selector.support_)\n",
        "print(selector.ranking_)\n"
      ],
      "metadata": {
        "id": "2y1Lp_fb56ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code: Feature selection using Genetic Algorithm\n",
        "from __future__ import print_function\n",
        "import numpy as num\n",
        "from sklearn import datasets, linear_model\n",
        "from genetic_selection import GeneticSelectionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "def main(X, y):\n",
        "  estimators = linear_model.LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
        "  selectors = GeneticSelectionCV(estimators,\n",
        "                                  cv=5,\n",
        "                                  verbose=2,\n",
        "                                  scoring=\"accuracy\",\n",
        "                                  max_features=7,\n",
        "                                  n_population=30,\n",
        "                                  crossover_proba=0.6,\n",
        "                                  mutation_proba=0.2,\n",
        "                                  n_generations=30,\n",
        "                                  crossover_independent_proba=0.6,\n",
        "                                  mutation_independent_proba=0.06,\n",
        "                                  tournament_size=4,\n",
        "                                  n_gen_no_change=20,\n",
        "                                  caching=True)\n",
        "  selectors = selectors.fit(X,y)\n",
        "  return(selectors.support_)\n",
        "if __name__ == \"__main__\":\n",
        "    data1 = datasets.load_wine()\n",
        "    X = data1.data\n",
        "    print(X.shape)\n",
        "    y = data1.target\n",
        "    print(y.shape)\n",
        "    selected=main(X, y)\n"
      ],
      "metadata": {
        "id": "auo7KFvq57d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code: Finding accuracy with feature selection using GA\n",
        "X_selected=X[:,selected]\n",
        "print(X_selected.shape)\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_selected, y, test_size=0.3)\n",
        "model1= linear_model.LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
        "model1.fit(X_train, y_train)\n",
        "predicted=model1.predict(X_test)\n",
        "TP, TN, FP, FN = 0, 0, 0, 0\n",
        "for i in range(y_test.shape[0]):\n",
        "  if(y_test[i]==predicted[i]):\n",
        "    if(y_test[i]==1):\n",
        "      TP+=1\n",
        "    else:\n",
        "      TN+=1\n",
        "  else:\n",
        "    if(predicted[i]==1):\n",
        "      FP+=1\n",
        "    else:\n",
        "      FN+=1\n",
        "acc= (TP + TN)/ (TP+TN+FP+FN)\n",
        "print(acc)\n"
      ],
      "metadata": {
        "id": "xgVedLdb6E-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code: Finding accuracy without feature selection\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3)\n",
        "model1= linear_model.LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
        "model1.fit(X_train, y_train)\n",
        "predicted=model1.predict(X_test)\n",
        "TP, TN, FP, FN = 0, 0, 0, 0\n",
        "for i in range(y_test.shape[0]):\n",
        "  if(y_test[i]==predicted[i]):\n",
        "    if(y_test[i]==1):\n",
        "      TP+=1\n",
        "    else:\n",
        "      TN+=1\n",
        "  else:\n",
        "    if(predicted[i]==1):\n",
        "      FP+=1\n",
        "    else:\n",
        "      FN+=1\n",
        "acc= (TP + TN)/ (TP+TN+FP+FN)\n",
        "print(acc)\n"
      ],
      "metadata": {
        "id": "YxxzUjcb6N3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = X[:50,:]\n",
        "X2 = X[50:,:]\n",
        "mean_feat1 = np.mean(X1, axis=0)\n",
        "mean_feat2 = np.mean(X2, axis=0)\n",
        "std_feat1 = np.std(X1, axis=0)\n",
        "std_feat2 = np.std(X2, axis=0)\n",
        "FDR=[ ((mean_feat1[i] - mean_feat2[i])**2)/(std_feat1[i]**2 + std_feat2[i]**2) for i in range(4)]\n",
        "print(FDR)\n"
      ],
      "metadata": {
        "id": "dHFe3BCO6UEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FDR_ordered = np.argsort(FDR)\n",
        "X_ = X[:, FDR_ordered[::-1]]\n",
        "print(FDR_ordered[::-1])\n"
      ],
      "metadata": {
        "id": "OR8dQfuZ6ZNQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}