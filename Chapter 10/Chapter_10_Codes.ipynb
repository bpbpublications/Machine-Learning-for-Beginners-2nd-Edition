{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ1OXFyHTZEH"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#Loading Data\n",
        "IRIS=load_iris()\n",
        "X=IRIS.data\n",
        "y=IRIS.target\n",
        "\n",
        "#Normalization\n",
        "max=[]\n",
        "min=[]\n",
        "S=X.shape\n",
        "for i in range(S[1]):\n",
        "    max.append(np.max(X[:,i]))\n",
        "    min.append(np.min(X[:,i]))\n",
        "for i in range(S[1]):\n",
        "    for j in range(S[0]):\n",
        "        X[j,i]=(X[j,i]-min[i])/(max[i]-min[i])\n",
        "arr=np.random.permutation(100)\n",
        "X=IRIS.data[arr,:]\n",
        "y=np.vstack((np.zeros((50,1)),np.ones((50,1))))\n",
        "y=y[arr]\n",
        "\n",
        "#Train test split\n",
        "X_train=X[:40,:]\n",
        "X_test=X[40:50,:]\n",
        "y_train=y[:40]\n",
        "y_test=y[40:50]\n",
        "X_train1=X[50:90,:]\n",
        "X_test1=X[90:100,:]\n",
        "y_train1=y[50:90]\n",
        "y_test1=y[90:100]\n",
        "X_train=np.vstack((X_train,X_train1))\n",
        "y_train=np.vstack((y_train,y_train1))\n",
        "X_test=np.vstack((X_test,X_test1))\n",
        "y_test=np.vstack((y_test,y_test1))\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "#Initialize weights and bias\n",
        "W1=np.random.random((4,2))\n",
        "W2=np.random.random((2,1))\n",
        "b1=np.random.random((1,2))\n",
        "b2=np.random.random((1,1))\n",
        "\n",
        "#Activation\n",
        "def f(u):\n",
        "    ans=1/(1+np.exp(-1*u))  #s=1\n",
        "    return ans\n",
        "#Learning\n",
        "y_pred=np.zeros(y_train.shape[0])\n",
        "for i in range(X_train.shape[0]):\n",
        "    input_sample=X_train[i,:]\n",
        "    u1=np.matmul(input_sample,W1)+b1      #1X2\n",
        "    v1=f(u1)   #1X2\n",
        "    u2=np.matmul(v1,W2)+b2  #1X1\n",
        "    v2=f(u2)   #1X1\n",
        "    if(v2>0.5):       #threshold=0.5\n",
        "        y_pred[i]=1\n",
        "    else:\n",
        "        y_pred[i]=0\n",
        "        W2=np.transpose(np.transpose(W2)+0.95*(y_train[i]-y_pred[i])*(v2)*(1-v2)*v1)   #s=1,learning rate=0.475\n",
        "        a=np.transpose(input_sample)  #4X1\n",
        "        b=(y_train[i]-y_pred[i])*(v2)*(1-v2)  #1X1\n",
        "        c=np.matmul(np.transpose(W2),np.matmul((np.transpose(v1)),(1-v1)))   #1X2\n",
        "        e=np.matmul(b,c)  #1X2\n",
        "inp=np.zeros((4,1))\n",
        "for j in range(a.shape[0]):\n",
        "    inp[j]=a[j]\n",
        "    delta=np.matmul(inp,e)\n",
        "    W1=W1+0.95*delta\n",
        "    b2=b2-0.1*y_pred[i]            #learning rate=0.1\n",
        "    b1=b1-0.1*y_pred[i]            #learning rate=0.1\n",
        "print(W2)  #2X1\n",
        "print(W1)  #4X2\n",
        "\n",
        "#Testing\n",
        "corr=0\n",
        "for i in range(X_test.shape[0]):\n",
        "    input_sample=X_test[i,:]\n",
        "    u1=np.matmul(input_sample,W1)+b1      #1X2\n",
        "    v1=f(u1)   #1X2\n",
        "    u2=np.matmul(v1,W2)+b2  #1X1\n",
        "    v2=f(u2)   #1X1\n",
        "    if(v2>0.5):       #threshold=0.5\n",
        "        y_pred[i]=1\n",
        "    else:\n",
        "        y_pred[i]=0\n",
        "    if(y_test[i]==y_pred[i]):\n",
        "        corr+=1\n",
        "acc=corr/(y_test.shape[0])   #accuracy\n",
        "print(acc)\n",
        "\n",
        "#Performance Measures\n",
        "      TP=0\n",
        "      TN=0\n",
        "      FN=0\n",
        "FP=0\n",
        "for i in range(len(y_test)):\n",
        "    if(y_test[i]==y_pred[i]):\n",
        "       if(y_test[i]==1):\n",
        "           TP+=1\n",
        "       else:\n",
        "           TN+=1\n",
        "    else:\n",
        "       if(y_pred[i]==1):\n",
        "           FP+=1\n",
        "       else:\n",
        "           FN+=1\n",
        "acc=(TP+TN)/(TP+TN+FP+FN)      #accuracy\n",
        "print(acc)\n",
        "sens=TP/(TP+FN)                #sensitivity\n",
        "print(sens)\n",
        "spec=TN/(TN+FP)                #specificity\n",
        "print(spec)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 1: IRIS DATA, Two classes, Normalization, MLP\n",
        "from sklearn.datasets import load_iris\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Loading the data\n",
        "IRIS=load_iris()\n",
        "X=IRIS.data\n",
        "y=IRIS.target\n",
        "\n",
        "#Normalization\n",
        "max=[]\n",
        "min=[]\n",
        "S=X.shape\n",
        "for i in range(S[1]):\n",
        "    max.append(np.max(X[:,i]))\n",
        "    min.append(np.min(X[:,i]))\n",
        "for i in range(S[1]):\n",
        "    for j in range(S[0]):\n",
        "        X[j,i]=(X[j,i]-min[i])/(max[i]-min[i])\n",
        "\n",
        "# shuffling and creating test and train data\n",
        "arr=np.random.permutation(100)\n",
        "X=IRIS.data[arr,:]\n",
        "y=np.vstack((np.zeros((50,1)),np.ones((50,1))))\n",
        "y=y[arr]\n",
        "X_train=X[:40,:]\n",
        "X_test=X[40:50,:]\n",
        "y_train=y[:40]\n",
        "y_test=y[40:50]\n",
        "X_train1=X[50:90,:]\n",
        "X_test1=X[90:100,:]\n",
        "y_train1=y[50:90]\n",
        "y_test1=y[90:100]\n",
        "X_train=np.vstack((X_train,X_train1))\n",
        "y_train=np.vstack((y_train,y_train1))\n",
        "X_test=np.vstack((X_test,X_test1))\n",
        "y_test=np.vstack((y_test,y_test1))\n",
        "#print(X_train.shape)\n",
        "\n",
        "#Classification\n",
        "clf=MLPClassifier(solver='lbfgs',alpha=1e-3,hidden_layer_sizes=(3, 2), random_state=1)\n",
        "clf.fit(X_train, y_train)\n",
        "predicted=clf.predict(X_test)\n",
        "\n",
        "#Performance evaluation\n",
        "TP=0\n",
        "TN=0\n",
        "FN=0\n",
        "FP=0\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    if(y_test[i]==predicted[i]):\n",
        "        if(y_test[i]==1):\n",
        "            TP+=1\n",
        "        else:\n",
        "            TN+=1\n",
        "    else:\n",
        "        if(predicted[i]==1):\n",
        "            FP+=1\n",
        "        else:\n",
        "            FN+=1\n",
        "acc=(TP+TN)/(TP+TN+FP+FN)      #accuracy\n",
        "print(acc)\n",
        "sens=TP/(TP+FN)                #sensitivity\n",
        "print(sens)\n",
        "spec=TN/(TN+FP)                #specificity\n",
        "print(spec)"
      ],
      "metadata": {
        "id": "08zkh-lzTb6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 2: IRIS DATA, two classes, Normalization, Train-test split, MLP\n",
        "from sklearn.datasets import load_iris\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "fromsklearn.model_selection import train_test_split\n",
        "importnumpy as np\n",
        "import math\n",
        "\n",
        "#Loading the data\n",
        "IRIS=load_iris()\n",
        "X=IRIS.data[:100,:]\n",
        "y=IRIS.target[:100]\n",
        "\n",
        "#Normalization\n",
        "max=[]\n",
        "min=[]\n",
        "S=X.shape\n",
        "for i in range(S[1]):\n",
        "    max.append(np.max(X[:,i]))\n",
        "    min.append(np.min(X[:,i]))\n",
        "for i in range(S[1]):\n",
        "    for j in range(S[0]):\n",
        "        X[j,i]=(X[j,i]-min[i])/(max[i]-min[i])\n",
        "\n",
        "#Train test split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=4)\n",
        "#Classification\n",
        "clf=MLPClassifier(solver='lbfgs',alpha=1e-3,hidden_layer_sizes=(3, 2),random_state=1)\n",
        "clf.fit(X_train, y_train)\n",
        "predicted=clf.predict(X_test)\n",
        "\n",
        "#Performance measures\n",
        "TP=0\n",
        "TN=0\n",
        "FN=0\n",
        "FP=0\n",
        "for i in range(len(y_test)):\n",
        "    if(y_test[i]==predicted[i]):\n",
        "        if(y_test[i]==1):\n",
        "            TP+=1\n",
        "        else:\n",
        "            TN+=1\n",
        "     else:\n",
        "         if(predicted[i]==1):\n",
        "            FP+=1\n",
        "         else:\n",
        "            FN+=1\n",
        "acc=(TP+TN)/(TP+TN+FP+FN)      #accuracy\n",
        "print(acc)\n",
        "sens=TP/(TP+FN)                #sensitivity\n",
        "print(sens)\n",
        "spec=TN/(TN+FP)                #specificity\n",
        "print(spec)\n"
      ],
      "metadata": {
        "id": "Z4zMS9ehTiLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 3: Breast Cancer Dataset, Two classes, Normalization, MLP\n",
        "rom sklearn.datasets import load_breast_cancer\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "importnumpy as np\n",
        "import math\n",
        "\n",
        "#Load Data\n",
        "dataset=load_breast_cancer()\n",
        "X=dataset.data\n",
        "y=dataset.target\n",
        "\n",
        "#Normalization\n",
        "max=[]\n",
        "min=[]\n",
        "S=X.shape\n",
        "for i in range(S[1]):\n",
        "    max.append(np.max(X[:,i]))\n",
        "    min.append(np.min(X[:,i]))\n",
        "for i in range(S[1]):\n",
        "    for j in range(S[0]):\n",
        "        X[j,i]=(X[j,i]-min[i])/(max[i]-min[i])\n",
        "\n",
        "# Train Test Split\n",
        "X_train=X[:400,:]\n",
        "X_test=X[400:,:]\n",
        "y_train=y[:400]\n",
        "y_test=y[400:]\n",
        "\n",
        "#Classify\n",
        "clf=MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(5, 2),random_state=1)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "#Performance Measures\n",
        "predicted=clf.predict(X_test)\n",
        "TP=0\n",
        "TN=0\n",
        "FN=0\n",
        "FP=0\n",
        "for i in range(len(y_test)):\n",
        "    if(y_test[i]==predicted[i]):\n",
        "        if(y_test[i]==1):\n",
        "            TP+=1\n",
        "        else:\n",
        "            TN+=1\n",
        "     else:\n",
        "        if(predicted[i]==1):\n",
        "           FP+=1\n",
        "        else:\n",
        "           FN+=1\n",
        "acc=(TP+TN)/(TP+TN+FP+FN)      #accuracy\n",
        "print(acc)\n",
        "sens=TP/(TP+FN)                #sensitivity\n",
        "print(sens)\n",
        "spec=TN/(TN+FP)                #specificity\n",
        "print(spec)\n",
        "\n"
      ],
      "metadata": {
        "id": "ExyDm2z2TnTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 4: Breast Cancer Dataset, Two classes, Normalization, K-Fold Split, MLP\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "importnumpy as np\n",
        "fromsklearn.model_selection import KFold\n",
        "import math\n",
        "\n",
        "#Load Data\n",
        "dataset=load_breast_cancer()\n",
        "X=dataset.data\n",
        "y=dataset.target\n",
        "\n",
        "#K Fold Validation\n",
        "kf=KFold(n_splits=10,random_state=None,shuffle=False)\n",
        "kf.get_n_splits(X)\n",
        "accur=[]\n",
        "specificity=[]\n",
        "senstivity=[]\n",
        "for train_index, test_index in kf.split(X):\n",
        "#print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)\n",
        "X_train, X_test = X[train_index], X[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "clf=MLPClassifier(solver='lbfgs',alpha=1e-3,hidden_layer_sizes=(8, 2))\n",
        "clf.fit(X_train,y_train)\n",
        "predicted=clf.predict(X_test)\n",
        "TP=0\n",
        "TN=0\n",
        "FN=0\n",
        "FP=0\n",
        "for i in range(len(y_test)):\n",
        "    if(y_test[i]==predicted[i]):\n",
        "        if(y_test[i]==1):\n",
        "            TP+=1\n",
        "        else:\n",
        "            TN+=1\n",
        "    else:\n",
        "        if(predicted[i]==1):\n",
        "            FP+=1\n",
        "        else:\n",
        "            FN+=1\n",
        "acc=(TP+TN)/(TP+TN+FP+FN)\n",
        "accur.append(acc)\n",
        "if((TP+FN)!=0):\n",
        "    sens=TP/(TP+FN)\n",
        "else:\n",
        "    sens=0\n",
        "senstivity.append(sens)\n",
        "if((TN+FP)!=0):\n",
        "    spec=TN/(TN+FP)\n",
        "else:\n",
        "    spec=0\n",
        "specificity.append(spec)\n",
        "print(np.mean(accur))\n",
        "print(np.mean(senstivity))\n",
        "print(np.mean(specificity))\n"
      ],
      "metadata": {
        "id": "wtYo5PkPTw3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cd9lbJeRT0pN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}